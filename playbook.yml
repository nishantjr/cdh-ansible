- hosts: all
  vars:
    - db_password: db
  become: true
  tasks:

#### Base system install #######################################################
  - name: 'Disable IPv6'
    sysctl:
      name: net.ipv6.conf.all.disable_ipv6
      value: 1
      reload: yes
  - name: 'Disable firewall'
    service: name=firewalld enabled=false state=stopped

  - name: 'Install packages'
    yum: name={{item}}  state=latest
    with_items:
      - tcl
      - wget
      - git
      - ant
      - maven
      - make
      - gcc-c++
      - gcc
      - binutils
      - libX11-devel
      - libXpm-devel
      - libXft-devel
      - libXext-devel

      - gcc-gfortran
      - openssl-devel
      - pcre-devel
      - mesa-libGL-devel
      - glew-devel
      - mysql-devel
      - fftw-devel
      - graphviz-devel
      - avahi-compat-libdns_sd-devel
      - python-devel
      - libxml2-devel

      - java-1.8.0-openjdk-devel
      - mysql-connector-java
      - MySQL-python

  - name: 'Enable CDH and mysql community release repositories'
    yum: name={{item}}  state=present
    with_items:
      - https://archive.cloudera.com/cdh5/one-click-install/redhat/7/x86_64/cloudera-cdh-5-0.x86_64.rpm
      - https://dev.mysql.com/get/mysql-community-release-el7-5.noarch.rpm

  - name: 'Install mysql-community-server'
    yum: name=mysql-community-server state=latest
  - name: 'Copy MySql configuration'
    template:
      src: 'config/my.conf'
      dest: '/etc/my.conf'
      owner: root
      group: root
      mode: 'u=rw,g=r,o=r'
  - name: 'Enable and start mysqld service'
    service: name=mysqld enabled=yes state=started
  - name: 'Set mysql root password'
    mysql_user:
      name: root
      password: '{{db_password}}'
      state: present
##### TODO: This doesn't work on the second run, because the password has changed
    ignore_errors: yes

##### Install Hadoop and friends ###############################################

  - name: 'Install Hadoop'
    yum: name={{item}} state=latest
    with_items:
    - hadoop
    - hadoop-hdfs-namenode
    - hadoop-hdfs-datanode
    - hadoop-hdfs-secondarynamenode
    - hadoop-yarn-resourcemanager
    - hadoop-yarn-nodemanager
    - hadoop-mapreduce-historyserver
    - hadoop-httpfs

    - zookeeper
    - zookeeper-server

    - hbase 
    - hbase-master
    - hbase-regionserver
    - hbase-thrift
    - hbase-rest

    - hive
    - hive-metastore
    - hive-server2
    - hive-hbase

    - pig

  - file: path=/etc/hadoop/conf.stat480/ state=directory
  - name: 'Copy hadoop conf'
    template:
      src: '{{item}}'
      dest: '/etc/hadoop/conf.stat480/{{item | basename}}'
    with_fileglob:
      - config/hadoop/*
  - alternatives: name=hadoop-conf link=/etc/hadoop/conf path=/etc/hadoop/conf.stat480

  - file: path=/etc/hbase/conf.stat480/ state=directory
  - name: 'Copy hbase conf'
    template:
      src: '{{item}}'
      dest: '/etc/hbase/conf.stat480/{{item | basename}}'
    with_fileglob:
      - config/hbase/*
  - alternatives: name=hbase-conf link=/etc/hbase/conf path=/etc/hbase/conf.stat480

  - file: path=/etc/hive/conf.stat480/ state=directory
  - name: 'Copy hive conf'
    template:
      src: '{{item}}'
      dest: '/etc/hive/conf.stat480/{{item | basename}}'
    with_fileglob:
      - config/hive/*
  - alternatives: name=hive-conf link=/etc/hive/conf path=/etc/hive/conf.stat480

#### WARNING: This is destructive: Should we put this in a separate playbook?
  - name: Format HDFS
    command: /usr/bin/hdfs namenode -format
    args:
      creates: "/var/lib/hadoop-hdfs/cache/hdfs/dfs/name/current/VERSION"
    become_user: hdfs
  - service: name={{item}} state=started enabled=yes
    with_items:
     - hadoop-hdfs-namenode
     - hadoop-hdfs-secondarynamenode
     - hadoop-hdfs-datanode
  - name: Check if hdfs has been initialized
    command: hadoop fs -test -f /user/oozie/share/lib/mapreduce-streaming/hadoop-streaming.jar
    register: hdfs_inited
  - name: Init HDFS 
    command: /usr/lib/hadoop/libexec/init-hdfs.sh
    when: hdfs_inited.rc == 1

    # Allow users some power but not the ability to delete other tables. See:
    # http://www.cloudera.com/content/www/en-us/documentation/enterprise/latest/topics/cdh_ig_filesystem_perm.html
  - name: Create hive/warehouse directory
    command: hadoop fs -mkdir -p /user/hive/warehouse
    become_user: hdfs
  - command: hadoop fs -chmod 1777 /user/hive/warehouse
    become_user: hdfs

  - pam_limits: domain={{item.user}} limit_type=- limit_item={{item.name}} value={{item.value}}
    with_items:
      - { user: hbase,     name: nofile,    value: 32768 }
      - { user: hbase,     name: nproc,     value: 32768 }
      - { user: hdfs,      name: nofile,    value: 32768 }
      - { user: hbase,     name: nproc,     value: 32768 }

#### Setup Hive
  - name: 'Create DB for Hive'
    mysql_db:
      name: metastore
      state: present
      target: /usr/lib/hive/scripts/metastore/upgrade/mysql/hive-schema-1.1.0.mysql.sql
      login_password: '{{db_password}}'
  - name: 'Set MySql Hive password'
    mysql_user:
      name: hive
      password: '{{db_password}}'
      state: present
      priv: 'metastore.*:ALL'
      login_password: '{{db_password}}'
